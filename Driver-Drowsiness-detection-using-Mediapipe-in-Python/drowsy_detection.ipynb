{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# interpretation of drowsy detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "process方法实现了疲劳检测的核心算法\n",
    "1. 处理输入帧：通过mp处理当前的视频帧，提取面部的关键点\n",
    "2. 计算EAR：计算眼睛的EAR指标以检测疲劳状态\n",
    "3. 管理疲劳时间：累计疲劳时间，并在时间超过设定值的时候播放警报\n",
    "4. 动态更新状态：根据EAR指标更新状态和界面信息\n",
    "5. 可视化信息：在视频帧上绘制与检测相关的文本和眼睛关键点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# streamlit_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "with col1:\n",
    "    ctx = webrtc_streamer(\n",
    "        key=\"drowsiness-detection\",\n",
    "        # key = \"local-stream\",\n",
    "        video_frame_callback=video_frame_callback,\n",
    "        audio_frame_callback=audio_frame_callback,\n",
    "        # rtc_configuration={\"iceServers\": [{\"urls\": [\"stun:stun.l.google.com:19302\"]}]},  # Add this to config for cloud deployment.\n",
    "        media_stream_constraints={\"video\": {\"height\": {\"ideal\": 480}}, \"audio\": True},\n",
    "        # media_stream_constraints={\"video\": True, \"audio\": True},\n",
    "        video_html_attrs=VideoHTMLAttributes(autoPlay=True, controls=False, muted=False),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码主要是实现了一个视频流实时处理的框架，流程如下：\n",
    "1. 视频流的启动：\n",
    "   - webrtc_streamer是Streamlit-webrtc提供的一个组件，用于通过WebRTC处理实时视频和音频流\n",
    "   - 他启动了一个WebRTC会话，捕获视频流并将每一帧传递到指定的回调函数中\n",
    "2. 视频流处理：\n",
    "   - video_frame_callback是视频流处理的回调函数，webtrc_streamer捕获到的视频帧会传递给他进行处理。\n",
    "   - 在video_frame_callback中，我们会调用video_handler的process去处理帧\n",
    "     - process方法对帧进行计算\n",
    "     - 返回处理后的帧以及是否需要播放警报的标志"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lock: 使用锁来保护共享状态的更新，确保线程安全"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三个模块之间的Link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. webtrc_streamer:\n",
    "   - 核心作用：捕获音视频流并处理他们\n",
    "   - 调用video_frame_callback来处理每一帧的视频\n",
    "   - 最终的处理结果会通过webrtc实时传输回客户端\n",
    "2. video_frame_callback:\n",
    "   - 接受webtrc_streamer传来的每一帧视频，进行处理\n",
    "   - 利用video_handler来完成具体的业务逻辑\n",
    "3. video_handler\n",
    "   - 专门负责对于单帧视频的核心处理（eye/mouth）\n",
    "   - process方法封装了业务逻辑，如各种计算以及返回处理结果\n",
    "- webtrc_streamer是连接用户设备摄像头/麦克风和程序逻辑之间的brige\n",
    "- 他不断地从用户设备获取视频帧，将帧传递给video_frame_callback处理，然后video_frame_callback将处理后的帧返回到用户设备显示"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
