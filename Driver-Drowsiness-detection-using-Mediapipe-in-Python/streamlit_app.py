import os
import av
import threading
import streamlit as st
import streamlit_nested_layout
from streamlit_webrtc import VideoHTMLAttributes, webrtc_streamer # åœ¨streamlitåº”ç”¨ä¸­å®ç°webrtcåŠŸèƒ½ï¼Œæ”¯æŒè¯•è¯•éŸ³è§†æµ

from audio_handling import AudioFrameHandler
from drowsy_detection import VideoFrameHandler
# from ads import css_string


# Define the audio file to use.
eye_alarm_file_path = os.path.join("audio", "wake_up.wav")
mouth_alarm_file_path = os.path.join("audio", "are_you_tried.wav")
# Streamlit Components
st.set_page_config(
    page_title="Drowsiness Detection ",
    page_icon="https://learnopencv.com/wp-content/uploads/2017/12/favicon.png",
    layout="wide",  # centered, wide
    initial_sidebar_state="expanded",
)


col1, col2 = st.columns(spec=[6, 2], gap="medium") # ç¬¬ä¸€åˆ—å 6ä¸ªå•ä½ï¼Œç¬¬äºŒåˆ—å 2ä¸ªå•ä½ï¼Œæ€»å®½åº¦ä¸º8

with col1:
    st.title("Drowsiness Detection!!!ğŸ¥±ğŸ˜ªğŸ˜´")
    with st.container():
        c1, c2 = st.columns(spec=[1, 1])
        with c1:
            # The amount of time (in seconds) to wait before sounding the alarm.è­¦æŠ¥å‰çš„ç­‰å¾…æ—¶é—´
            # åœ¨ç¬¬ä¸€åˆ—c1ä¸­ï¼Œæ·»åŠ ä¸€ä¸ªæ»‘å—ï¼Œç”¨äºè®¾ç½®ç­‰å¾…æ—¶é—´0-5ï¼Œé»˜è®¤1ï¼Œæ­¥é•¿0ï¼Œ25
            WAIT_TIME = st.slider("Seconds to wait before sounding alarm:", 0.0, 5.0, 1.0, 0.25)
            
        with c2:
            # Lowest valid value of Eye Aspect Ratio. Ideal values [0.15, 0.2].EARé˜ˆå€¼
            EAR_THRESH = st.slider("Eye Aspect Ratio threshold:", 0.0, 0.4, 0.18, 0.01)
            MOU_THRSH = st.slider("Mouth Aspect Ratio threshold",0.0, 0.4, 0.2, 0.01)

thresholds = {
    "EAR_THRESH": EAR_THRESH, # åˆ¤æ–­ç”¨æˆ·æ˜¯å¦å¤„äºå›°å€¦çŠ¶æ€çš„é˜ˆå€¼
    "WAIT_TIME": WAIT_TIME, # æ£€æµ‹åˆ°å›°å€¦åï¼Œå‡ºå‘è­¦æŠ¥å‰çš„ç­‰å¾…æ—¶é—´
    "MOU_THRESH": MOU_THRSH # å˜´å·´å¼ å¼€çš„ç¨‹åº¦åˆ¤å®šä¸ºæ‰“å“ˆæ¬ çš„é˜ˆå€¼
}

# For streamlit-webrtc
video_handler = VideoFrameHandler()
audio_handler = AudioFrameHandler()

lock = threading.Lock()  # For thread-safe access & to prevent race-condition.
shared_state = {"play_eye_alarm": False,
                "play_mouth_alarm": False}

# avæ¨¡å—ï¼šavæ˜¯ä¸€ä¸ªpyåº“ï¼Œç”¨äºå¤„ç†éŸ³é¢‘å’Œè§†é¢‘æ•°æ®ï¼Œæä¾›äº†å¯¹å¤šç§åª’ä½“æ ¼å¼çš„æ”¯æŒï¼Œå¹¶å…è®¸ç”¨æˆ·è¯»å–ï¼Œå†™å…¥å’Œå¤„ç†éŸ³è§†é¢‘æµ
# av.VideoFrame: av.VideoFrameæ˜¯avæ¨¡å—ä¸­çš„ä¸€ä¸ªç±»ï¼Œè¡¨ç¤ºè§†é¢‘å¸§

# è¯¥å‡½æ•°æ¥å—ä¸€ä¸ªav.VideoFrameç±»å‹çš„å‚æ•°frame,è¿™æ˜¯ä¸€ä¸ªè¡¨ç¤ºè§†é¢‘å¸§çš„å¯¹è±¡
# video_frame_callbackæ˜¯ä¸€ä¸ªå›è°ƒå‡½æ•°ï¼Œé€šå¸¸ç”¨äºå¤„ç†ä»è§†é¢‘æµä¸­è¯»å–çš„æ¯ä¸€å¸§çš„æ•°æ®

def video_frame_callback(frame: av.VideoFrame):
    frame = frame.to_ndarray(format="bgr24")  # Decode and convert frame to RGB

    frame, play_eye_alarm, play_mouth_alarm = video_handler.process(frame, thresholds)  # Process frame
    with lock:
        shared_state["play_eye_alarm"] = play_eye_alarm  # Update shared state
        shared_state["play_mouth_alarm"] = play_mouth_alarm

    return av.VideoFrame.from_ndarray(frame, format="bgr24")  # Encode and return BGR frame


def audio_frame_callback(frame: av.AudioFrame):
    with lock:  # access the current â€œplay_alarmâ€ state
        play_eye_alarm = shared_state["play_eye_alarm"]
        play_mouth_alarm = shared_state["play_mouth_alarm"]
    # if play_eye_alarm == True:
    #     audio_handler.update_audio_file_path(eye_alarm_file_path)
    #     new_frame: av.AudioFrame = audio_handler.process(frame, play_sound=play_eye_alarm) # é€šè¿‡play_soundå³play_alarmçŠ¶æ€æ¥æ‰§è¡ŒæŠ¥è­¦å™¨
    # else:
    #     new_frame: av.AudioFrame = audio_handler.process(frame, False)
    if play_eye_alarm == True:
        audio_handler.update_audio_file_path(eye_alarm_file_path)
    new_frame: av.AudioFrame = audio_handler.process(frame, play_sound=play_eye_alarm) # é€šè¿‡play_soundå³play_alarmçŠ¶æ€æ¥æ‰§è¡ŒæŠ¥è­¦å™¨

    if play_mouth_alarm == True:
        audio_handler.update_audio_file_path(mouth_alarm_file_path)
    new_frame: av.AudioFrame = audio_handler.process(frame, play_sound=play_mouth_alarm) # é€šè¿‡play_soundå³play_alarmçŠ¶æ€æ¥æ‰§è¡ŒæŠ¥è­¦å™¨
    return new_frame


# https://github.com/whitphx/streamlit-webrtc/blob/main/streamlit_webrtc/config.py
with col1:
    ctx = webrtc_streamer(
        key="drowsiness-detection",
        # key = "local-stream",
        video_frame_callback=video_frame_callback,
        audio_frame_callback=audio_frame_callback,
        # rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},  # Add this to config for cloud deployment.
        media_stream_constraints={"video": {"height": {"ideal": 480}}, "audio": True},
        # media_stream_constraints={"video": True, "audio": True},
        video_html_attrs=VideoHTMLAttributes(autoPlay=True, controls=False, muted=False),
    )
